{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e317fd9d-abcd-4f7f-b039-ce41497802b1",
   "metadata": {},
   "source": [
    "### Installing Jupyter\n",
    "\n",
    "Get up and running on your computer\n",
    "\n",
    "[Jupyter Install Guide](https://jupyter.org/install)\n",
    "\n",
    "Project Jupyter’s tools are available for installation via the Python Package Index, the leading repository of software created for the Python programming language.\n",
    "\n",
    "This link above uses instructions with pip, the recommended installation tool for Python. If you require environment management as opposed to just installation, look into conda, mamba, pipenv, and Homebrew.\n",
    "\n",
    "\n",
    "## JupyterLab[](https://jupyter.org/install#jupyterlab)\n",
    "\n",
    "Install JupyterLab with `pip`:\n",
    "\n",
    "```\n",
    "pip install jupyterlab\n",
    "```\n",
    "\n",
    "**Note**: If you install JupyterLab with conda or mamba, we recommend using [the conda-forge channel](https://conda-forge.org/).\n",
    "\n",
    "Once installed, launch JupyterLab with:\n",
    "\n",
    "```\n",
    "jupyter lab\n",
    "```\n",
    "\n",
    "## Jupyter Notebook[](https://jupyter.org/install#jupyter-notebook)\n",
    "\n",
    "Install the classic Jupyter Notebook with:\n",
    "\n",
    "```\n",
    "pip install notebook\n",
    "```\n",
    "\n",
    "To run the notebook:\n",
    "\n",
    "```\n",
    "jupyter notebook\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74b54814-0625-4234-9faf-c47c3ecc12c8",
   "metadata": {},
   "source": [
    "## Ollama: Local LLM Platform\n",
    "\n",
    "Ollama is a platform that allows running large language models(LLM) locally on your machine, providing access to models like **Llama3.2** without needing cloud infrastructure.\n",
    "It is commonly used for natural language processing tasks such as text generation or chatbot development.\n",
    "\n",
    "### Steps to use Ollama Models: \n",
    "\n",
    "-  Download Ollama\n",
    "\t- https://ollama.com/download\n",
    "- Install Ollama for Python\n",
    "\n",
    "```\n",
    "     pip install ollama\n",
    "```\n",
    "\n",
    "-  Download an LLM Model from Ollama\n",
    "\tVisit the [Ollama Librarys](https://ollama.com/library) to find available models\n",
    "\tExample to pull the LIama3.2 model: \n",
    "```\n",
    "\tollama pull llama3.2\n",
    "```\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1c0a076d-7495-4c85-967d-1fc9b497319c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import os\n",
    "import requests\n",
    "from IPython.display import Markdown, display\n",
    "\n",
    "from langchain_openai import ChatOpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "54bc1f30-a557-4395-b94e-a22db46856b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "OLLAMA_BASE_URL = \"http://localhost:11434/v1\"\n",
    "OLLAMA_API_KEY = \"ollama\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f6cd0e2a-f24b-4fb3-bc0b-bb59b5aa2965",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ChatOpenAI(\n",
    "    model=\"mistral\",\n",
    "    temperature=0.8,\n",
    "    max_tokens=None,\n",
    "    timeout=None,\n",
    "    max_retries=2,\n",
    "    api_key=OLLAMA_API_KEY,\n",
    "    base_url=\"http://localhost:11434/v1\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcc4d492-cc82-4e02-876b-60547d909f24",
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = [  \n",
    "\t(  \n",
    "\t\t\"system\",  \n",
    "\t\t\"You are a helpful assistant that translates English to . Translate the user sentence.\",  \n",
    "\t),  \n",
    "    (\n",
    "    \"human\", \"I love Artificial intelligence.\"\n",
    "    ),  \n",
    "]  \n",
    "ai_msg = llm.invoke(messages)\n",
    "ai_msg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce374ce3-1a68-46a6-ab96-a8d6fbd7be19",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(ai_msg.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1af08ab4-1584-4b23-91a1-daddd2b6e992",
   "metadata": {},
   "outputs": [],
   "source": [
    "display(Markdown(f\"** LLM Resonse: **\\n\\n{ai_msg.content}\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
